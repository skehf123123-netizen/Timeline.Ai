import pandas as pd
import difflib  # í…ìŠ¤íŠ¸ ìœ ì‚¬ë„ ë¹„êµ ë„êµ¬

# --- ì„¤ì •: ê¸°ë³¸ ë¹„êµ ëŒ€ìƒ íŒŒì¼ ì´ë¦„ (ì›í•˜ë©´ í•¨ìˆ˜ ì¸ìë¡œë„ ë°›ì„ ìˆ˜ ìˆìŒ) ---
TRUTH_FILE = "truth.xlsx"      # ì‚¬ëŒì´ ê²€ìˆ˜í•œ ì •ë‹µ ì—‘ì…€ (ìˆ˜ì •ë³¸)
AI_FILE = "ai_result.xlsx"     # AIê°€ ë°©ê¸ˆ ë¶„ì„í•œ ì—‘ì…€ (ì›ë³¸)

# ë§¤ì¹­ ê¸°ì¤€ ìµœì†Œ ìœ ì‚¬ë„ (ì´ ì ìˆ˜ ë¯¸ë§Œì´ë©´ ë§¤ì¹­ ì‹¤íŒ¨ë¡œ ê°„ì£¼)
MIN_MATCH_SIMILARITY = 50.0

# ê°€ì¤‘ì¹˜ ì„¤ì •
WEIGHT_CONTENT = 0.5    # ë‚´ìš© (50%)
WEIGHT_DATE = 0.2       # ë‚ ì§œ (20%)
WEIGHT_IMPORTANCE = 0.2 # ì¤‘ìš”ë„ (20%)
WEIGHT_SENDER = 0.1     # í™”ì (10%)


def calculate_similarity(s1, s2) -> float:
    """ë‘ ë¬¸ì¥ì˜ ìœ ì‚¬ë„ë¥¼ 0~100ì  ì‚¬ì´ë¡œ ë°˜í™˜"""
    if pd.isna(s1):
        s1 = ""
    if pd.isna(s2):
        s2 = ""
    return difflib.SequenceMatcher(None, str(s1), str(s2)).ratio() * 100


def normalize_date(d) -> str:
    """
    ë‚ ì§œ ë¹„êµìš© ì •ê·œí™” í•¨ìˆ˜
    - datetime, ë¬¸ìì—´ ë“± ëª¨ë‘ 'YYYY-MM-DD' í˜•ì‹ ì• 10ê¸€ìë§Œ ì‚¬ìš©
    - NaN, None ë“±ì€ ë¹ˆ ë¬¸ìì—´ë¡œ ì²˜ë¦¬
    """
    if pd.isna(d):
        return ""
    return str(d).strip()[:10]


def find_best_match_for_row(truth_row: pd.Series,
                            df_ai: pd.DataFrame,
                            used_ai_indices: set):
    """
    ì •ë‹µ í–‰(truth_row)ê³¼ ê°€ì¥ ë¹„ìŠ·í•œ AI í–‰ ì°¾ê¸°
    - ì´ë¯¸ ë§¤ì¹­ëœ AI í–‰ì€ ê±´ë„ˆëœ€
    - content ê¸°ì¤€ ìœ ì‚¬ë„ ìƒìœ„ 1ê°œ ì„ íƒ
    - MIN_MATCH_SIMILARITY ë¯¸ë§Œì´ë©´ ë§¤ì¹­ ì‹¤íŒ¨ ì²˜ë¦¬
    """
    best_idx = None
    best_sim = -1.0
    truth_content = truth_row.get("content", "")

    for idx, ai_row in df_ai.iterrows():
        if idx in used_ai_indices:
            continue  # ì´ë¯¸ ë§¤ì¹­ëœ ê±´ íŒ¨ìŠ¤

        ai_content = ai_row.get("content", "")
        sim = calculate_similarity(truth_content, ai_content)

        if sim > best_sim:
            best_sim = sim
            best_idx = idx

    # ìœ ì‚¬ë„ê°€ ë„ˆë¬´ ë‚®ìœ¼ë©´ ë§¤ì¹­ ì•ˆ í•¨
    if best_idx is None or best_sim < MIN_MATCH_SIMILARITY:
        return None, best_sim

    return best_idx, best_sim


def evaluate_performance(truth_file: str = TRUTH_FILE,
                         ai_file: str = AI_FILE,
                         output_file: str = "ì •í™•ë„_í‰ê°€_ë¦¬í¬íŠ¸.xlsx"):
    """
    truth_file vs ai_file ì—‘ì…€ì„ ë¹„êµí•˜ì—¬ ì •í™•ë„ë¥¼ í‰ê°€í•˜ê³ ,
    ìƒì„¸/ìš”ì•½ ì‹œíŠ¸ë¥¼ ê°€ì§„ ë¦¬í¬íŠ¸ ì—‘ì…€(output_file)ì„ ìƒì„±í•œë‹¤.
    """
    print(f"ğŸ” í‰ê°€ ì‹œì‘: {truth_file} vs {ai_file}")

    # 1. ì—‘ì…€ ë¶ˆëŸ¬ì˜¤ê¸°
    try:
        df_truth = pd.read_excel(truth_file)
        df_ai = pd.read_excel(ai_file)
    except Exception as e:
        print(f"âŒ íŒŒì¼ ì½ê¸° ì‹¤íŒ¨: {e}\n   â†’ íŒŒì¼ ì´ë¦„/ê²½ë¡œ/ì—‘ì…€ í˜•ì‹(xlsx) í™•ì¸ í•„ìš”")
        return

    if df_truth.empty:
        print("âš ï¸ ê²½ê³ : ì •ë‹µ(truth) ì—‘ì…€ì´ ë¹„ì–´ ìˆìŠµë‹ˆë‹¤. í‰ê°€ë¥¼ ì§„í–‰í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        return

    print(f"ğŸ“‚ ì •ë‹µ ë°ì´í„°: {len(df_truth)}ê°œ / AI ë°ì´í„°: {len(df_ai)}ê°œ")

    used_ai_indices = set()
    detail_rows = []
    total_score = 0.0
    matched_count = 0

    # 2. ì±„ì  ë£¨í”„
    for i in range(len(df_truth)):
        truth_row = df_truth.iloc[i]
        row_id = i + 1

        best_ai_idx, best_sim = find_best_match_for_row(truth_row, df_ai, used_ai_indices)

        # ë§¤ì¹­ ì‹¤íŒ¨ (AIê°€ ì´ ì •ë‹µ ë©”ì‹œì§€ë¥¼ ëª» ë§ì¶¤)
        if best_ai_idx is None:
            detail_rows.append({
                "ID": row_id,
                "ë§¤ì¹­ìƒíƒœ": "âŒ ë¯¸íƒì§€",
                "ì •ë‹µ_ë‚´ìš©": truth_row.get("content"),
                "AI_ë‚´ìš©": "-",
                "ë‚´ìš©_ìœ ì‚¬ë„": 0.0,
                "ë‚ ì§œ_ì¼ì¹˜": "X",
                "ì¤‘ìš”ë„_ì¼ì¹˜": "X",
                "í™”ì_ìœ ì‚¬ë„": 0.0,
                "ìµœì¢…_ì ìˆ˜": 0.0,
            })
            continue

        # ë§¤ì¹­ ì„±ê³µ
        ai_row = df_ai.loc[best_ai_idx]
        used_ai_indices.add(best_ai_idx)
        matched_count += 1

        # --- ì ìˆ˜ ê³„ì‚° ---
        # 1) ë‚´ìš© ì ìˆ˜
        content_score = best_sim  # 0~100

        # 2) ë‚ ì§œ ì ìˆ˜ (normalize_date ì ìš©)
        date_truth = normalize_date(truth_row.get("date"))
        date_ai = normalize_date(ai_row.get("date"))
        date_match = (date_truth == date_ai)
        date_score = 100.0 if date_match else 0.0

        # 3) ì¤‘ìš”ë„ ì ìˆ˜
        gt_imp = str(truth_row.get("importance")).strip()
        ai_imp = str(ai_row.get("importance")).strip()
        imp_match = (gt_imp == ai_imp)
        imp_score = 100.0 if imp_match else 0.0

        # 4) í™”ì ì ìˆ˜ (ì´ë¦„ì´ ì‚´ì§ ë‹¬ë¼ë„ ìœ ì‚¬ë„ ê¸°ë°˜ìœ¼ë¡œ í‰ê°€)
        sender_score = calculate_similarity(truth_row.get("sender"), ai_row.get("sender"))

        # ìµœì¢… ê°€ì¤‘ì¹˜ í•©ì‚°
        final_row_score = (
            content_score * WEIGHT_CONTENT +
            date_score * WEIGHT_DATE +
            imp_score * WEIGHT_IMPORTANCE +
            sender_score * WEIGHT_SENDER
        )
        total_score += final_row_score

        detail_rows.append({
            "ID": row_id,
            "ë§¤ì¹­ìƒíƒœ": f"âœ… ë§¤ì¹­ë¨ (AI idx={best_ai_idx})",
            "ì •ë‹µ_ë‚´ìš©": truth_row.get("content"),
            "AI_ë‚´ìš©": ai_row.get("content"),
            "ë‚´ìš©_ìœ ì‚¬ë„": round(content_score, 1),
            "ë‚ ì§œ_ì¼ì¹˜": "O" if date_match else "X",
            "ì¤‘ìš”ë„_ì¼ì¹˜": "O" if imp_match else "X",
            "í™”ì_ìœ ì‚¬ë„": round(sender_score, 1),
            "ìµœì¢…_ì ìˆ˜": round(final_row_score, 1),
        })

    # 3. ê²°ê³¼ ìš”ì•½
    unmatched_ai_count = len(df_ai) - len(used_ai_indices)
    avg_score = total_score / matched_count if matched_count > 0 else 0.0
    coverage = matched_count / len(df_truth) * 100 if len(df_truth) > 0 else 0.0

    print("\n------------------------------------------------")
    print(f"ğŸ“Š í‰ê·  ì •í™•ë„: {avg_score:.2f}ì  (0~100)")
    print(f"ğŸ¯ ì •ë‹µ ë§¤ì¹­ë¥ : {coverage:.1f}% ({matched_count}/{len(df_truth)})")
    print(f"âš ï¸ ë§¤ì¹­ ì•ˆ ëœ AI í–‰(í™˜ê° ê°€ëŠ¥ì„±): {unmatched_ai_count}ê°œ")
    print("------------------------------------------------")

    # 4. ì—‘ì…€ ì €ì¥
    df_detail = pd.DataFrame(detail_rows)
    df_summary = pd.DataFrame([
        {"í•­ëª©": "í‰ê·  ì •í™•ë„", "ê°’": f"{avg_score:.2f}ì "},
        {"í•­ëª©": "ë§¤ì¹­ ì„±ê³µë¥ ", "ê°’": f"{coverage:.1f}%"},
        {"í•­ëª©": "AI í™˜ê°(ë§¤ì¹­ ì•ˆ ëœ AI í–‰) ê°œìˆ˜", "ê°’": unmatched_ai_count},
        {"í•­ëª©": "ë‚´ìš© ê°€ì¤‘ì¹˜", "ê°’": WEIGHT_CONTENT},
        {"í•­ëª©": "ë‚ ì§œ ê°€ì¤‘ì¹˜", "ê°’": WEIGHT_DATE},
        {"í•­ëª©": "ì¤‘ìš”ë„ ê°€ì¤‘ì¹˜", "ê°’": WEIGHT_IMPORTANCE},
        {"í•­ëª©": "í™”ì ê°€ì¤‘ì¹˜", "ê°’": WEIGHT_SENDER},
    ])

    with pd.ExcelWriter(output_file, engine="openpyxl") as writer:
        df_detail.to_excel(writer, sheet_name="ìƒì„¸", index=False)
        df_summary.to_excel(writer, sheet_name="ìš”ì•½", index=False)

    print(f"ğŸ“‚ '{output_file}' ì €ì¥ ì™„ë£Œ!")


if __name__ == "__main__":
    evaluate_performance()
